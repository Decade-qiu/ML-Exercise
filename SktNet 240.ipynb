{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "features = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', \n",
    "            'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'cnt']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = pd.DataFrame(scaler.fit_transform(train_data[features]), columns=features)\n",
    "test_scaled = pd.DataFrame(scaler.transform(test_data[features]), columns=features)\n",
    "\n",
    "\n",
    "def create_sequences(data, target, input_len, output_len):\n",
    "    \"\"\"\n",
    "    生成滑动窗口输入数据和目标值\n",
    "    \"\"\"\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - input_len - output_len):\n",
    "        x.append(data[i:i + input_len])\n",
    "        y.append(target[i + input_len:i + input_len + output_len])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "input_len = 96  \n",
    "output_len = 240 \n",
    "\n",
    "x_train, y_train = create_sequences(train_scaled[features[:-1]].values, train_scaled['cnt'].values, input_len, output_len)\n",
    "x_test, y_test = create_sequences(test_scaled[features[:-1]].values, test_scaled['cnt'].values, input_len, output_len)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)  \n",
    "print(\"y_train shape:\", y_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv1D, Add, Attention\n",
    "import tensorflow as tf\n",
    "\n",
    "class CountMinSketchLayer(layers.Layer):\n",
    "    def __init__(self, hash_functions=3, sketch_size=128, **kwargs):\n",
    "        super(CountMinSketchLayer, self).__init__(**kwargs)\n",
    "        self.hash_functions = hash_functions\n",
    "        self.sketch_size = sketch_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # 初始化哈希权重和偏移量\n",
    "        self.hash_weights = self.add_weight(\n",
    "            shape=(self.hash_functions, feature_dim),\n",
    "            initializer=\"random_uniform\",\n",
    "            trainable=False,\n",
    "            name=\"hash_weights\"\n",
    "        )\n",
    "        self.hash_bias = self.add_weight(\n",
    "            shape=(self.hash_functions,),\n",
    "            initializer=\"random_uniform\",\n",
    "            trainable=False,\n",
    "            name=\"hash_bias\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        input_len = tf.shape(inputs)[1]\n",
    "        feature_dim = inputs.shape[-1]\n",
    "\n",
    "        # 计算哈希索引\n",
    "        hash_indices = tf.math.floormod(\n",
    "            tf.matmul(inputs, tf.transpose(self.hash_weights)) + self.hash_bias,\n",
    "            self.sketch_size\n",
    "        )\n",
    "        hash_indices = tf.cast(hash_indices, dtype=tf.int32)\n",
    "        sketch = tf.zeros((batch_size, self.sketch_size, feature_dim))\n",
    "\n",
    "        for i in range(self.hash_functions):\n",
    "            updates = tf.gather_nd(inputs, tf.where(hash_indices[:, :, i] < self.sketch_size))\n",
    "            indices = tf.where(hash_indices[:, :, i] < self.sketch_size)\n",
    "            sketch = tf.tensor_scatter_nd_add(sketch, indices, updates)\n",
    "\n",
    "        return sketch\n",
    "\n",
    "def build_enhanced_lstm_with_sketch(input_len, feature_dim, output_len):\n",
    "    inputs = layers.Input(shape=(input_len, feature_dim))\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    sketch = CountMinSketchLayer(hash_functions=3, sketch_size=128)(x)\n",
    "\n",
    "\n",
    "    x = layers.LSTM(128, return_sequences=True, activation='tanh')(sketch)\n",
    "    compressed1 = layers.Dense(64, activation='relu')(x)  \n",
    "\n",
    "    attn_output = Attention()([compressed1, compressed1])  \n",
    "    x = Add()([compressed1, attn_output]) \n",
    "    x = layers.LSTM(128, return_sequences=True, activation='tanh')(x)\n",
    "    compressed2 = layers.Dense(64, activation='relu')(x)  \n",
    "    x = layers.LSTM(256, activation='tanh')(compressed2)\n",
    "\n",
    "    outputs = layers.Dense(output_len)(x)  \n",
    "\n",
    "    return models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 构建 LSTM 模型\n",
    "# ===========================\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "best_history = None  \n",
    "best_val_loss = float('inf') \n",
    "\n",
    "num_experiments = 10\n",
    "\n",
    "for i in range(num_experiments):\n",
    "    print(f\"Starting Experiment {i + 1}/{num_experiments}...\")\n",
    "    \n",
    "    model = build_enhanced_lstm_with_sketch(\n",
    "        input_len=input_len, \n",
    "        feature_dim=len(features) - 1, \n",
    "        output_len=output_len\n",
    "    )\n",
    "    # model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "\n",
    "    current_min_val_loss = min(history.history['val_loss'])\n",
    "    if current_min_val_loss < best_val_loss:\n",
    "        best_val_loss = current_min_val_loss\n",
    "        best_history = history \n",
    "    \n",
    " \n",
    "    mse, mae = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Experiment {i + 1} - MSE: {mse:.4f}, MAE: {mae:.4f}\")\n",
    "    \n",
    "    # 保存结果\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "# 计算均值和标准差\n",
    "mse_mean = np.mean(mse_scores)\n",
    "mse_std = np.std(mse_scores)\n",
    "mae_mean = np.mean(mae_scores)\n",
    "mae_std = np.std(mae_scores)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(\"MSE Scores:\", mse_scores)\n",
    "print(f\"Mean MSE: {mse_mean:.4f}, Std MSE: {mse_std:.4f}\")\n",
    "print(\"MAE Scores:\", mae_scores)\n",
    "print(f\"Mean MAE: {mae_mean:.4f}, Std MAE: {mae_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_history\n",
    "\n",
    "epochs = len(history.history['loss'])\n",
    "# 绘制训练损失曲线\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(epochs), history.history['loss'], label='Training Loss', linewidth=2)\n",
    "# plt.plot(range(epochs), history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "plt.title('Loss over Epochs', fontsize=18)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "final_predictions = np.zeros_like(test_scaled['cnt'].values)\n",
    "counts = np.zeros_like(test_scaled['cnt'].values)\n",
    "\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    start_idx = i + input_len \n",
    "    end_idx = start_idx + output_len  \n",
    "    for j in range(output_len):\n",
    "        final_predictions[start_idx + j] += y_pred[i][j]\n",
    "        counts[start_idx + j] += 1\n",
    "final_predictions /= counts\n",
    "\n",
    "true_values = test_scaled['cnt'].values[input_len:] \n",
    "predicted_values = final_predictions[input_len:]\n",
    "\n",
    "\n",
    "time_st = 250\n",
    "time_ed = time_st + 250\n",
    "true_values_ = true_values[time_st:time_ed]\n",
    "predicted_values_ = predicted_values[time_st:time_ed]\n",
    "\n",
    "\n",
    "# 本地保存真实值和对比值\n",
    "file = open(\"mymodel/tp1.txt\", \"w\")\n",
    "for i in range(len(true_values_)):\n",
    "    file.write(str(true_values_[i]) + \" \" + str(predicted_values_[i]) + \"\\n\")\n",
    "file.close()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(true_values_, label=\"Ground Truth\", linestyle='-', marker='o', markersize=3, alpha=0.7, color='b',linewidth=1.5)\n",
    "plt.plot(predicted_values_, label=\"Prediction\", linestyle='--', marker='x', markersize=4, alpha=1, color='r',linewidth=2)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time Step\", fontsize=14)\n",
    "plt.ylabel(\"Rental Count\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.title(\"Overall Bike Rental Prediction\", fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
